akka {

  loggers = ["akka.event.Logging$DefaultLogger"]
  loglevel = "INFO"

  actor {
    provider = cluster
  }

  remote {
    enabled-transports = ["akka.remote.netty.tcp"]
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      hostname = ${?AKKA_HOSTNAME}
      port = 2552
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://nsdb@"${akka.remote.netty.tcp.hostname}":2552"]

    //    roles = ["node"]

    # auto downing is NOT safe for production deployments.
    # you may want to use it during development, read more about it in the docs.
    #
    # auto-down-unreachable-after = 10s

    client.receptionist {
      # Actor name of the ClusterReceptionist actor, /system/receptionist
      name = receptionist

      # Start the receptionist on members tagged with this role.
      # All members are used if undefined or empty.
      role = ""

      # The receptionist will send this number of contact points to the client
      number-of-contacts = 3

      # The actor that tunnel response messages to the client will be stopped
      # after this time of inactivity.
      response-tunnel-receive-timeout = 30s

      # The id of the dispatcher to use for ClusterReceptionist actors.
      # If not specified default dispatcher is used.
      # If specified you need to define the settings of the actual dispatcher.
      use-dispatcher = ""

      # How often failure detection heartbeat messages should be received for
      # each ClusterClient
      heartbeat-interval = 2s

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # The ClusterReceptionist is using the akka.remote.DeadlineFailureDetector, which
      # will trigger if there are no heartbeats within the duration
      # heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with
      # the default settings.
      acceptable-heartbeat-pause = 13s

      # Failure detection checking interval for checking all ClusterClients
      failure-detection-interval = 2s
    }
  }

  log-dead-letters = 10
  log-dead-letters-during-shutdown = on

  extensions = ["akka.cluster.client.ClusterClientReceptionist"]

  http.server.idle-timeout = 1 hour
}

nsdb {

  http {
    interface = "0.0.0.0"
    interface = ${?HTTP_INTERFACE}
    port = 9000
    port = ${?HTTP_PORT}
    api.path = "api"
    api.version = "v0.1"
  }

  index {
    base-path= "target/index"
  }

  commit-log {
    enabled = true
    serializer = "io.radicalbit.nsdb.commit_log.StandardCommitLogSerializer"
    writer = "io.radicalbit.nsdb.commit_log.RollingCommitLogFileWriter"
    directory = "/tmp/"
    max-size = 50000
  }

  metadata {
    storage = ""
  }

  global.timeout = 10 seconds
  global.timeout = ${?GLOBAL_TIMEOUT}
  rpc-endpoint.timeout = 10 seconds
  rpc-endpoint.timeout = ${?RPC_TIMEOUT}
  rpc-akka-endpoint.timeout = 10 seconds
  rpc-akka-endpoint.timeout = ${?RPC_AKKA_TIMEOUT}

  read-coordinatoor.timeout = 10 seconds
  read-coordinatoor.timeout = ${?READ_COORDINATOR_TIMEOUT}
  write-coordinator.timeout = 10 seconds
  write-coordinator.timeout = ${?WRITE_COORDINATOR_TIMEOUT}
  namespace-schema.timeout = 10 seconds
  namespace-schema.timeout = ${?NAMESPACE_SCHEMA_TIMEOUT}
  namespace-data.timeout = 10 seconds
  namespace-data.timeout = ${?NAMESPACE_DATA_TIMEOUT}
  publisher.timeout = 10 seconds
  publisher.timeout = ${?PUBLISHER_TIMEOUT}
  publisher.scheduler.interval = 5 seconds

  nsdb.write.scheduler.interval = 5 seconds

  stream.timeout = 10 seconds
  stream.timeout = ${?STREAM_TIMEOUT}
}
